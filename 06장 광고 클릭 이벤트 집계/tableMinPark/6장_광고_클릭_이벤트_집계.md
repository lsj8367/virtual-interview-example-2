

## 1. 설계 목표 및 요구사항 분석

### 1.1 핵심 목표

- 비즈니스 가치: RTB 및 광고 데이터 분석을 위한 핵심 데이터 제공
- 속도 vs 정확성
    - RTB 시스템: 속도가 생명으로 1초 미만 응답 필요
    - 집계 시스템: 광고 과금 및 보고서용이므로 데이터 정확성이 최우선이며 수 분 정도의 지연은 허용됨

### 1.2 규모 추정

- 트래픽: 일간 능동 사용자 10억 명 -> 하루 10억 건의 클릭 이벤트 발생 가정
- QPS: 평균 10,000 QPS, 피크 시 50,000 QPS 예상
- 저장 용량: 이벤트당 0.1KB 가정 시 일간 100GB, 월간 3TB 필요

### 1.3 주요 기능

1. 집계: 지난 M분간 특정 ad_id의 클릭 수 합산
2. 랭킹: 지난 1분간 가장 많이 클릭된 상위 100개 광고 반환
3. 필터링: ip, country, user_id 등 속성 기반 필터링 지원

---

## 2. 전체 아키텍처 및 데이터 모델

### 2.1 데이터 모델링 전략: Raw vs Aggregated

두 가지 방식 중 하나만 고르는 게 아니라 용도에 따라 둘 다 가져가는 전략을 취함

- 원시 데이터
    - 특징: 모든 클릭 이벤트를 그대로 저장
    - 장점: 데이터 손실 없음, 디버깅 및 재계산 가능
    - 단점: 용량이 거대하고 질의 속도 느림
    - 용도: 백업, 시스템 복구용
- 집계 결과 데이터
    - 특징: 매분/매시간 단위로 묶어서 저장
    - 장점: 용량이 작고 질의 속도가 매우 빠름
    - 단점: 데이터 축약으로 인한 정보 손실, 원본 복구 불가
    - 용도: 실시간 대시보드, 서비스용

### 2.2 데이터베이스 선정

- 요구사항: 읽기보다는 쓰기 연산이 압도적으로 많음
- 선택: 카산드라 또는 InfluxDB
    - 이유: 대규모 쓰기 처리에 최적화되어 있으며 시계열 데이터를 다루기에 적합함, 관계형 DB는 이 규모의 쓰기를 감당하기 어려움
    - 대안: 원시 데이터는 ORC, Parquet 형식으로 아마존 S3에 저장하여 비용 절감

### 2.3 비동기 처리 구조

트래픽 급증에 대응하기 위해 메시지 큐를 활용해 컴포넌트 간 결합을 끊음

> 전체 흐름
로그 모니터 -> Kafka 1 (Raw) -> 집계 서비스 -> Kafka 2 (Aggregated) -> DB
>
- Kafka 2의 역할: 집계 결과를 DB에 바로 넣지 않고 큐에 넣는 이유
    - Atomic Commit & Exactly-once: 집계 서비스가 DB에 넣다가 장애가 나면 데이터가 꼬일 수 있음, 이를 방지하고 '정확히 한 번' 처리를 보장하기 위한 버퍼 역할을 함

---

## 3. 핵심 상세 설계

### 3.1 집계 로직: MapReduce & DAG 모델

단일 서버로는 계산이 불가능하므로 분산 처리가 필수이며 Map-Aggregate-Reduce 모델 적용

1. Map (분배): ad_id를 해싱하여 같은 광고는 항상 같은 노드로 가도록 분배
2. Aggregate (집계): 각 노드 메모리에서 카운팅 수행
3. Reduce (축약): 각 노드에서 산출된 상위 N개 결과를 모아서 최종적인 전체 랭킹 산출

### 3.2 스트리밍 아키텍처: Lambda vs Kappa

과거 데이터 재처리 이슈를 어떻게 해결할 것인가

- Lambda 아키텍처: 실시간 레이어와 배치 레이어 별도 운영, 안전하지만 로직이 중복되어 유지보수가 어려움
- Kappa 아키텍처: 모든 것은 스트림이다
    - 배치 레이어를 제거하고 과거 데이터도 스트림으로 다시 흘려보내서 처리함
    - 이때 실시간 처리와 재처리 작업이 섞이지 않도록 재계산 전용 집계 서비스를 별도로 띄움

### 3.3 시간 관리: Event Time vs Processing Time

- 문제: 네트워크 지연으로 이벤트 발생 시각과 서버 도착 시각이 다름
- 결정: 이벤트 발생 시각 기준 집계가 원칙
    - 서버 시각을 쓰면 쉽지만 늦게 도착한 데이터 때문에 집계가 부정확해짐
- Watermark 기법: 늦게 도착하는 이벤트를 처리하기 위해 집계 윈도우를 바로 닫지 않고 일정 시간만큼 기다려줌
    - Trade-off: 워터마크를 길게 잡으면 정확도는 올라가지만 결과가 나오는 대기 시간이 길어짐

### 3.4 집계 윈도우

- 텀블링 윈도: 겹치지 않는 고정 시간 구간 (예: 1분 단위 집계)
- 슬라이딩 윈도: 시간이 흐르며 겹쳐지는 구간 (예: 지난 1분간 상위 100개)

---

## 4. 안정성 및 확장성 확보

### 4.1 전달 보증: Exactly-Once

과금 시스템에서 데이터 중복은 치명적임

- 장애 시나리오: 집계 노드가 Kafka 오프셋을 100까지 처리하고 결과를 보냈는데 오프셋을 저장하기 직전에 죽음 -> 되살아난 노드는 다시 100번부터 읽음 -> 중복 집계 발생
- 해결책: 분산 트랜잭션
    - 집계 결과 전송과 오프셋 저장을 하나의 트랜잭션으로 묶음
    - 다운스트림에서 수신 확인을 받은 후에만 오프셋을 저장하는 방식 사용

### 4.2 핫스팟 문제 해결

특정 인기 광고에 클릭이 몰리면 해당 이벤트를 처리하는 노드만 과부하가 걸림

- 해결 알고리즘
    1. 자원 관리자가 노드 과부하 감지
    2. 추가 자원 할당
    3. 원래 노드는 이벤트를 쪼개서 여러 노드로 분산
    4. 각 노드가 부분 집계한 후 다시 하나로 합침

### 4.3 결함 내성

- 문제: 인메모리 집계 중 노드가 죽으면 메모리 데이터 증발
- 해결: 스냅숏 활용
    - Kafka 오프셋뿐만 아니라 상위 광고 목록 같은 시스템 상태를 주기적으로 디스크에 저장
    - 장애 발생 시 처음부터 다시 계산하는 대신 마지막 스냅숏부터 복구하여 시간 단축

---

## 5. 데이터 검증 및 마무리

### 5.1 데이터 조정

실시간 시스템은 복잡해서 100% 정확하기 어려울 수 있음

- 방법: 매일 밤 원시 데이터를 기반으로 배치 작업을 돌림
- 비교: 배치로 계산된 정답과 실시간 집계 결과를 비교하여 차이가 있으면 보정함

### 5.2 대안적 설계

- 데이터 저장: 하이브에 저장
- 질의 계층: 일래스틱서치로 빠른 검색 지원
- 집계 엔진: 클릭하우스나 드루이드 같은 OLAP 전용 DB 활용

---

### 요약 및 배운 점

1. MapReduce의 활용: 빅데이터 처리는 결국 나눠서 계산하고 합치는 과정
2. Kappa 아키텍처: 유지보수 복잡도를 줄이기 위해 배치 레이어를 없애고 스트림으로 통일하는 추세
3. Exactly-once의 중요성: 돈과 관련된 시스템에서는 중복을 막기 위한 트랜잭션 관리가 필수
4. Reconciliation: 실시간 시스템의 불안정성을 보완하기 위해 배치 기반의 검증 로직이 꼭 필요